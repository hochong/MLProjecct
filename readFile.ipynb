{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import numpy as np\n",
    "\n",
    "#read class\n",
    "def readTranscript(filename='genes_transcript.xlsx'):\n",
    "    sheet = xlrd.open_workbook(filename).sheet_by_index(0)\n",
    "    nRows = sheet.nrows\n",
    "    my_class_label = []\n",
    "    my_class_value = []\n",
    "    for rowNum in range(0,nRows):\n",
    "        rowList = []\n",
    "        row = sheet.row_values(rowNum)\n",
    "        rowLabel = row.pop(0)\n",
    "        my_class_label.append([rowLabel])\n",
    "        for el in row:\n",
    "            rowList.append([el])\n",
    "        rowList = np.array(rowList)\n",
    "        my_class_value.append(rowList)\n",
    "    my_class_label = np.array(my_class_label)\n",
    "    my_class_value = np.array(my_class_value)\n",
    "    #print(my_class_label)\n",
    "    #print(my_class_value)\n",
    "    return my_class_label, my_class_value\n",
    "\n",
    "#read data\n",
    "def readData(filename='gene_data.xlsx'):\n",
    "    sheet = xlrd.open_workbook(filename).sheet_by_index(0)\n",
    "    nRows = sheet.nrows\n",
    "    my_data_value = []\n",
    "    for rowNum in range(0,nRows):\n",
    "        rowList = []\n",
    "        row = sheet.row_values(rowNum)\n",
    "        for el in row:\n",
    "            rowList.append([el])\n",
    "        rowList = np.array(rowList)\n",
    "        my_data_value.append(rowList)\n",
    "    my_data_value = np.array(my_data_value)\n",
    "    #print(my_data_value)\n",
    "    return my_data_value\n",
    "\n",
    "class_name, class_value = readTranscript()\n",
    "data_value = readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi square feature selection\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "#select 100 features\n",
    "def chisq_feature_selection(X, y,numoffeature=100):\n",
    "    #normalize data\n",
    "    #mms = MinMaxScaler()\n",
    "    #Xnorm = mms.fit_transform(X)\n",
    "    Xnorm = X\n",
    "    #chi square\n",
    "    chisq = SelectKBest(chi2, k=numoffeature)\n",
    "    Xchi = chisq.fit_transform(Xnorm, y)\n",
    "    return Xchi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.copy(data_value)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove header(name of each sample)\n",
    "data1 = np.delete(data, 0,axis=0)\n",
    "#print(data1)\n",
    "\n",
    "#remove first row(ID row)\n",
    "data2 = np.delete(data1, 0, axis=1)\n",
    "#print(data2)\n",
    "\n",
    "#turn 3dd list to 2d list\n",
    "#print(data2.shape)\n",
    "data3 = np.reshape(data2, (data2.shape[0], data2.shape[1],))\n",
    "#print(data3.shape)\n",
    "\n",
    "#transpose to match the class\n",
    "data4 = data3.transpose()\n",
    "#print(data4)\n",
    "\n",
    "#change from str to float\n",
    "data_float = data4.astype(np.float)\n",
    "#print(data_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select gleason (total) score\n",
    "y = class_value[3]\n",
    "#print(y)\n",
    "\n",
    "#change from str to float\n",
    "y_float = y.astype(np.float)\n",
    "#print(y_float)\n",
    "\n",
    "#reshape y to 1d\n",
    "y_float = np.reshape(y_float, (y_float.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = chisq_feature_selection(data_float, y_float)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494,)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#train_data, test_data, train_class, test_class = train_test_split(X, y_float, test_size=0.1, random_state=20201217)\n",
    "\n",
    "#kfold, no shuffle to get the same result every time\n",
    "#kfold = KFold(n_splits=10, shuffle=False)\n",
    "#for train_index, test_index in kfold.split(train_data)\n",
    "print(y_float.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yahagi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42       0.48       0.48       0.48       0.51020408 0.53061224\n",
      " 0.48979592 0.51020408 0.46938776 0.55102041]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svmClassifier = svm.SVC()\n",
    "scores = cross_val_score(svmClassifier, X, y_float, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val with chi square\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "max_feature = 600\n",
    "svmClassifier = svm.SVC()\n",
    "\n",
    "#disable warning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "scoreList = []\n",
    "for fea in range(1, max_feature+1):\n",
    "    Xfea = chisq_feature_selection(data_float, y_float,fea)\n",
    "    \n",
    "    scores = cross_val_score(svmClassifier, X, y_float, cv=10)\n",
    "    scoreList.append(scores[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot result\n",
    "#print(scoreList)\n",
    "plt.figure()\n",
    "plt.title('cross val score under different number of features')\n",
    "plt.plot(range(1,max_feature+1),scoreList )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mutual information feature selection\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "#select 100 features\n",
    "def mutualInfo_feature_selection(X, y,numoffeature=100):\n",
    "    #normalize data\n",
    "    #mms = MinMaxScaler()\n",
    "    #Xnorm = mms.fit_transform(X)\n",
    "    Xnorm = X\n",
    "    #chi square\n",
    "    mutualInfo = SelectKBest(mutual_info_classif, k=numoffeature)\n",
    "    Xmutual = mutualInfo.fit_transform(Xnorm, y)\n",
    "    return Xmutual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val with mutual info\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "max_feature = 600\n",
    "svmClassifier = svm.SVC()\n",
    "\n",
    "#disable warning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "scoreList = []\n",
    "for fea in range(1, max_feature+1):\n",
    "    Xfea = mutualInfo_feature_selection(data_float, y_float, fea)\n",
    "    \n",
    "    scores = cross_val_score(svmClassifier, X, y_float, cv=10)\n",
    "    scoreList.append(scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f test feature selection\n",
    "from sklearn.feature_selection import f_classif\n",
    "#select 100 features\n",
    "def f_test_feature_selection(X, y,numoffeature=100):\n",
    "    #normalize data\n",
    "    #mms = MinMaxScaler()\n",
    "    #Xnorm = mms.fit_transform(X)\n",
    "    Xnorm = X\n",
    "    #chi square\n",
    "    f_test = SelectKBest(f_classif, k=numoffeature)\n",
    "    Xf = f_test.fit_transform(Xnorm, y)\n",
    "    return Xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val with f test\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "max_feature = 600\n",
    "svmClassifier = svm.SVC()\n",
    "\n",
    "#disable warning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "scoreList = []\n",
    "for fea in range(1, max_feature+1):\n",
    "    Xfea = f_test_feature_selection(data_float, y_float, fea)\n",
    "    \n",
    "    scores = cross_val_score(svmClassifier, X, y_float, cv=10)\n",
    "    scoreList.append(scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
